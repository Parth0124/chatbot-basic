{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import openai\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x10ded19d0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x10d9df290>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model='Gemma2-9b-It', groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Parth! It's nice to meet you. üëã\\n\\nAs a large language model, I'm always interested in learning more about people who work in data science. What kind of projects are you currently working on? Do you have a particular area of data science that you specialize in? ü§î  \\n\\nI'm eager to hear about your work! üòÑ\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 22, 'total_tokens': 99, 'completion_time': 0.14, 'prompt_time': 0.00282445, 'queue_time': 0.7439841890000001, 'total_time': 0.14282445}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-86445514-018e-401f-90f5-09dfd2320855-0', usage_metadata={'input_tokens': 22, 'output_tokens': 77, 'total_tokens': 99})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content = \"Hi, My name is Parth! I am a data scientist\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Parth, and you are a data scientist!  \\n\\nIs there anything else you'd like to tell me about your work? üòä \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 99, 'total_tokens': 133, 'completion_time': 0.061818182, 'prompt_time': 0.003971196, 'queue_time': 0.020339992, 'total_time': 0.065789378}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-711acf25-0286-40fa-bf34-de6882a2a40c-0', usage_metadata={'input_tokens': 99, 'output_tokens': 34, 'total_tokens': 133})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"Hi, My name is Parth! I am a data scientist\"),\n",
    "        AIMessage(content = \"Hi Parth, it's nice to meet you!\\n\\nThat's awesome that you're a data scientist. What kind of work do you do?  \\n\\nI'm always interested in learning more about how people use data to solve problems and make discoveries.\\n\"),\n",
    "        HumanMessage(content = \"IWhat is my name and what do i do?\"),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To differentiate between the chat history and the session history\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_msg_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = { 'configurable': {\"session_id\":\"chat_1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_msg_history.invoke(\n",
    "        [\n",
    "            HumanMessage(content = \"Hi, My name is Parth! I am a data scientist\"),\n",
    "        ], config=config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Parth! It's nice to meet you.  \\n\\nWhat kind of data science work do you do?  I'm always interested in learning more about how people are using AI and data to solve problems.\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Parth, and you're a data scientist! üòä  \\n\\nIs there anything else you'd like to tell me about yourself or your work? I'm eager to learn more.  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 90, 'total_tokens': 138, 'completion_time': 0.087272727, 'prompt_time': 0.002258072, 'queue_time': 0.020667808, 'total_time': 0.089530799}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-088dcf8d-e556-40c5-8021-4ec1094e936c-0', usage_metadata={'input_tokens': 90, 'output_tokens': 48, 'total_tokens': 138})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_msg_history.invoke(\n",
    "        [\n",
    "            HumanMessage(content = \"Hey, What is my name and what do i do?\"),\n",
    "        ], config=config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change the config session\n",
    "\n",
    "config1 = { 'configurable': {\"session_id\":\"chat_1\"}}\n",
    "response = with_msg_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"Hey, What is my name and what do i do?\"),\n",
    "    ], config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You told me your name is Parth, and that you're a data scientist!  \\n\\nDo you want to talk more about your work? I'm interested in hearing about what kind of data science projects you're working on. üòä  \\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change the config session\n",
    "\n",
    "config1 = { 'configurable': {\"session_id\":\"chat_2\"}}      ## Changed the session id\n",
    "response = with_msg_history.invoke( \n",
    "    [\n",
    "        HumanMessage(content = \"Hey, What is my name and what do i do?\"),\n",
    "    ], config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and no way to know your name or what you do.\\n\\nIf you'd like to tell me, I'm happy to learn! üòä\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change the config session\n",
    "\n",
    "config1 = { 'configurable': {\"session_id\":\"chat_2\"}}\n",
    "response = with_msg_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"Hey, My name is Walter White also known as Heisenberg. I am a high school chemistry teacher in J. P. Wynne High School, Mexico who turned into a methamphetamine manufacturer\"),\n",
    "    ], config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change the config session\n",
    "\n",
    "config1 = { 'configurable': {\"session_id\":\"chat_2\"}}\n",
    "response = with_msg_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"Hey, What is my name?\"),\n",
    "    ], config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You said your name is Walter White, also known as Heisenberg.  \\n\\nIs there anything else I can help you with?  üß†  \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change the config session\n",
    "\n",
    "config1 = { 'configurable': {\"session_id\":\"chat_2\"}}\n",
    "response = with_msg_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"Hey, What do i do?\"),\n",
    "    ], config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're a high school chemistry teacher at J. P. Wynne High School in Mexico, but you've also become a methamphetamine manufacturer, operating under the alias Heisenberg. \\n\\nIs there anything specific you'd like to discuss about your... dual profession? ü§î  Perhaps the challenges of keeping your two lives separate, or the risks involved in your chosen line of work?  \\n\\nRemember, I'm here to listen, even if your story is a bit... unconventional. ü§ê\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change the config session\n",
    "\n",
    "config1 = { 'configurable': {\"session_id\":\"chat_2\"}}\n",
    "response = with_msg_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"Hey, Where do i work?\"),\n",
    "    ], config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You work at J. P. Wynne High School in Mexico.  \\n\\n  Is there anything else you'd like to know about your current situation? Perhaps you'd like to discuss the challenges of teaching chemistry while also producing a highly illegal substance?  \\n\\n Remember, I'm here to listen without judgment. ü§´  \\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Added a template and a chain to invoke.                      \n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are helpfull assistant. Answer all the questions to the best of your ability.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Parth! It's nice to meet you.  \\n\\nI'm glad you're here. What can I do for you today?  I'll do my best to answer all your questions. üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 33, 'total_tokens': 83, 'completion_time': 0.090909091, 'prompt_time': 0.003581027, 'queue_time': 0.128620691, 'total_time': 0.094490118}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8b2de94a-365a-451e-ae03-1ee7f5ba34b8-0', usage_metadata={'input_tokens': 33, 'output_tokens': 50, 'total_tokens': 83})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'messages':[HumanMessage(content='Hi, my name is Parth')]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_msg_history = RunnableWithMessageHistory(chain, get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='It sounds like you have great taste in TV shows! \\n\\nI can definitely chat about \"How I Met Your Mother\" and \"The Vampire Diaries.\" What specifically about \"HIMYM\" are you enjoying? And which aspects of Damon Salvatore did you find so compelling?  \\n\\nI\\'m always eager to discuss movies and series, so feel free to ask me anything!  üòä \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 77, 'total_tokens': 159, 'completion_time': 0.149090909, 'prompt_time': 0.005293942, 'queue_time': 0.020329276, 'total_time': 0.154384851}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7eafed42-3b0c-4cb7-aaa0-87d93def2d23-0', usage_metadata={'input_tokens': 77, 'output_tokens': 82, 'total_tokens': 159})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response = with_msg_history.invoke(\n",
    "    [HumanMessage(content=\"I am currently watching how i met your mother. It is an american sitcom which falls under the comedy genre. I love watching movies and series. I loved The Vampire Diaries as well. I loved the character of Damon Salvatore i.e Ian Somerhakder\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't have access to your personal preferences or past conversations. So, I wouldn't know which show you like best!\\n\\nIs there a particular reason you're curious about which one is your favorite?  Perhaps you're trying to decide what to watch next? ü§î  I could help you brainstorm if you'd like! \\n\\n\\n\\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 174, 'total_tokens': 253, 'completion_time': 0.143636364, 'prompt_time': 0.01157558, 'queue_time': 0.020134757999999996, 'total_time': 0.155211944}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-314e3ace-eddf-4dd7-a00d-8681433ed031-0', usage_metadata={'input_tokens': 174, 'output_tokens': 79, 'total_tokens': 253})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response = with_msg_history.invoke(\n",
    "    [HumanMessage(content=\"Which is my favouraite show?\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Based on our conversation, you are currently engaged with the **comedy** genre through watching \"How I Met Your Mother\".  \\n\\nYou also mentioned enjoying \"The Vampire Diaries\", which falls under the **supernatural drama** genre.  \\n\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 267, 'total_tokens': 318, 'completion_time': 0.092727273, 'prompt_time': 0.02034863, 'queue_time': 0.021945055999999998, 'total_time': 0.113075903}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8fc8a0dd-47f2-41aa-a8e7-56cc688d5970-0', usage_metadata={'input_tokens': 267, 'output_tokens': 51, 'total_tokens': 318})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response = with_msg_history.invoke(\n",
    "    [HumanMessage(content=\"What genre am i currently engaged with\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are helpfull assistant. Answer all the questions to the best of your ability in {language}.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§™‡§æ‡§∞‡§•! \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§ú‡§æ‡§®‡§ï‡§∞ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•Å‡§à ‡§ï‡§ø ‡§Ü‡§™ ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§∏‡•Ç‡§ö‡§®‡§æ ‡§™‡•ç‡§∞‡•å‡§¶‡•ç‡§Ø‡•ã‡§ó‡§ø‡§ï‡•Ä ‡§∏‡§Ç‡§∏‡•ç‡§•‡§æ‡§® ‡§ß‡§æ‡§∞‡§µ‡§°, ‡§ï‡§∞‡•ç‡§®‡§æ‡§ü‡§ï ‡§Æ‡•á‡§Ç ‡§¨‡•Ä.‡§ü‡•á‡§ï ‡§ï‡•á ‡§™‡•ç‡§∞‡•Ä-‡§´‡§æ‡§á‡§®‡§≤ ‡§à‡§Ø‡§∞ ‡§Æ‡•á‡§Ç ‡§π‡•à‡§Ç‡•§  \\n\\n‡§Ü‡§™‡§ï‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡•Å‡§ù‡•á ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•ã‡§ó‡•Ä‡•§  \\n \\n‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? üòä \\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"Hey, I am Parth, a pre final year pursuing B.Tech at Indian Institute of Information Technology Dharwad, Karnataka\")], \"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§™‡§æ‡§∞‡•ç‡§•! ‡§Æ‡§≤‡§æ ‡§µ‡§æ‡§ü‡§§‡•á ‡§ï‡•Ä ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§Ü‡§£‡§ñ‡•Ä ‡§è‡§ï‡§æ ‡§Æ‡•ã‡§†‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡§ó‡§§‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§≤‡§¢‡§§ ‡§Ü‡§π‡§æ‡§§!  \\n\\n‡§Æ‡§≤‡§æ ‡§ñ‡•Ç‡§™ ‡§Ü‡§®‡§Ç‡§¶ ‡§Ü‡§π‡•á ‡§ï‡•Ä ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§Æ‡§≤‡§æ ‡§§‡•Å‡§Æ‡§ö‡•Ä ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§¶‡•á‡§ä‡§® ‡§∏‡•Å‡§∞‡•Å‡§µ‡§æ‡§§ ‡§ï‡•á‡§≤‡•Ä. ‡§Æ‡•Ä ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§ï‡•ã‡§£‡§§‡•ç‡§Ø‡§æ‡§π‡•Ä ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§∏‡•ã‡§°‡§µ‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§Ü‡§£‡§ø ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Æ‡§¶‡§§ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§â‡§§‡•ç‡§∏‡•Å‡§ï ‡§Ü‡§π‡•á.\\n\\n‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§ï‡§æ‡§Ø ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§Ü‡§π‡•á? üòä\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"Hey, I am Parth, a pre final year pursuing B.Tech at Indian Institute of Information Technology Dharwad, Karnataka\")], \"language\":\"Marathi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bonjour Parth ! \\n\\nEnchant√© de te rencontrer. C'est int√©ressant de savoir que tu es en derni√®re ann√©e de B.Tech au Indian Institute of Information Technology Dharwad, Karnataka. \\n\\nN'h√©site pas √† me poser tes questions, je ferai de mon mieux pour y r√©pondre.  Que puis-je faire pour toi aujourd'hui ? üòä\\n\\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"Hey, I am Parth, a pre final year pursuing B.Tech at Indian Institute of Information Technology Dharwad, Karnataka\")], \"language\":\"French\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ŸÖÿ±ÿ≠ÿ®ÿß ÿ®ŸêŸÉŸéÿå ÿ®ÿßÿ±ÿ´! Ÿäÿ≥ÿπÿØŸÜŸä ÿßŸÑÿ™ÿπÿ±ŸëŸÅ ÿπŸÑŸäŸÉŸé. ÿ£ŸÜÿß ÿ£Ÿèÿ≥ÿßÿπÿØŸÉ ÿ®ŸÉŸÑ ŸÖÿß ÿ£ÿ≥ÿ™ÿ∑Ÿäÿπ.\\n\\nÿ£ŸÜÿß ÿ£ŸèÿØÿ±ŸêŸÉ ÿ£ŸÜŸÉŸé ÿ∑ÿßŸÑÿ® ŸÅŸä ÿßŸÑÿ≥ŸÜÿ© ÿßŸÑÿ´ÿßŸÜŸäÿ© ŸÇÿ®ŸÑ ÿßŸÑÿ£ÿÆŸäÿ±ÿ© ŸÅŸä ÿ®ÿ±ŸÜÿßŸÖÿ¨ ÿßŸÑÿ®ŸÉÿßŸÑŸàÿ±ŸäŸàÿ≥ ŸÅŸä ÿ™ŸÇŸÜŸäÿ© ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÅŸä ŸÖÿπŸáÿØ ÿßŸÑŸáŸÜÿØÿ≥ÿ© ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™Ÿäÿ© ÿ®ŸÄ ÿØŸáÿ±ŸàÿßÿØÿå ŸÉÿßÿ±ŸÜÿßÿ™ÿßŸÉÿß. \\n\\nŸÖÿß ÿßŸÑÿ∞Ÿä ŸäŸÖŸÉŸÜŸÜŸä ÿ£ŸÜ ÿ£ŸÅÿπŸÑŸá ŸÑŸÖÿ≥ÿßÿπÿØÿ™ŸÉ ÿßŸÑŸäŸàŸÖÿü \\n\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"Hey, I am Parth, a pre final year pursuing B.Tech at Indian Institute of Information Technology Dharwad, Karnataka\")], \"language\":\"Arabic\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„Åì„Çì„Å´„Å°„ÅØ„ÄÅParth„Åï„Çì„ÄÇ\\n\\nIIIT Dharwad„ÅßB.TechÊúÄÁµÇÂ≠¶Âπ¥„Å®„ÅÆ„Åì„Å®„Åß„Åô„Å≠ÔºÅ \\n\\n‰Ωï„ÅãË≥™Âïè„Åå„ÅÇ„Çå„Å∞„ÄÅÊó•Êú¨Ë™û„ÅßËÅû„ÅÑ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂñú„Çì„Åß„ÅäÁ≠î„Åà„Åó„Åæ„Åô„ÄÇüòä \\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"Hey, I am Parth, a pre final year pursuing B.Tech at Indian Institute of Information Technology Dharwad, Karnataka\")], \"language\":\"japanese\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‰Ω†Â•ΩÔºåParthÔºÅÂæàÈ´òÂÖ¥ËÆ§ËØÜ‰Ω†„ÄÇ‰Ω†ÊòØÂç∞Â∫¶‰ø°ÊÅØÊäÄÊúØÂ≠¶Èô¢ËææÊãâÁì¶Âæ∑ÁöÑ‰∏âÂπ¥Á∫ßÂ≠¶ÁîüÂêóÔºü \\n\\nËØ∑ÈóÆ‰Ω†ÊÉ≥‰∫ÜËß£‰ªÄ‰πàÔºüÊàë‰ºöÂ∞ΩÂäõÁî®‰∏≠ÊñáÂõûÁ≠î‰Ω†ÁöÑÈóÆÈ¢ò„ÄÇ  \\n\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"Hey, I am Parth, a pre final year pursuing B.Tech at Indian Institute of Information Technology Dharwad, Karnataka\")], \"language\":\"Chinese\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_msg_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Æ‡•Ä ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§¶‡§§‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§Ø‡•á‡§•‡•á ‡§Ü‡§π‡•á! ‡§§‡•Å‡§Æ‡§ö‡§æ ‡§Æ‡•ç‡§π‡§£‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Æ‡§≤‡§æ ‡§Ü‡§®‡§Ç‡§¶ ‡§Ü‡§π‡•á ‡§ï‡•Ä ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§ï‡•ã‡§° ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§ö‡•á ‡§Ü‡§µ‡§°‡§§‡§æ ‡§Ü‡§£‡§ø ‡§è‡§ï MERN ‡§∏‡•ç‡§ü‡•Ö‡§ï ‡§°‡•á‡§µ‡•ç‡§π‡§≤‡§™‡§∞ ‡§Ü‡§£‡§ø ‡§°‡•á‡§ü‡§æ ‡§∏‡§æ‡§Ø‡§Ç‡§ü‡§ø‡§∏‡•ç‡§ü ‡§Ü‡§π‡§æ‡§§! ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û‡§§‡•á‡§§ ML ‡§Ö‡§≤‡•ç‡§ó‡•ã‡§∞‡§ø‡§¶‡§Æ, NLP, ‡§°‡•Ä‡§™ ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§Ü‡§£‡§ø ‡§ú‡§®‡§∞‡•á‡§ü‡§ø‡§µ‡•ç‡§π ‡§è‡§Ü‡§Ø ‡§Ø‡§æ‡§Ç‡§ö‡§æ ‡§∏‡§Æ‡§æ‡§µ‡•á‡§∂ ‡§Ü‡§π‡•á ‡§π‡•á ‡§ú‡§æ‡§£‡•Ç‡§® ‡§ò‡•á‡§£‡•á ‡§ñ‡•Ç‡§™ ‡§â‡§§‡•ç‡§§‡§Æ ‡§µ‡§æ‡§ü‡§≤‡•á. \\n\\n‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ‡§ï‡§°‡•á ‡§ï‡•ã‡§£‡§§‡•á‡§π‡•Ä ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§Ü‡§π‡•á‡§§ ‡§ï‡§æ? ‡§Æ‡•Ä ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§∏‡§∞‡•ç‡§µ‡§æ‡§Ç‡§®‡§æ ‡§â‡§§‡•ç‡§§‡§∞‡•á ‡§¶‡•á‡§£‡•ç‡§Ø‡§æ‡§ö‡§æ ‡§™‡•ç‡§∞‡§Ø‡§§‡•ç‡§® ‡§ï‡§∞‡•á‡§®. \\n\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "response = with_msg_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"I love to code. I am MERN Stack Developer and Data Scientist with expertise in ML Algorithms, NLP, Deep Learning and Generative AI\")], \"language\": \"Marathi\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's awesome! It sounds like you have a really exciting and in-demand skillset. \\n\\nWhat kind of projects are you working on these days? Are you using generative AI for anything interesting? \\n\\nI'm always eager to learn more about what people are doing with these technologies.  üòä \\n\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "response = with_msg_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"I love to code. I am MERN Stack Developer and Data Scientist with expertise in ML Algorithms, NLP, Deep Learning and Generative AI\")], \"language\": \"English\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on what you said, your working profession is a **MERN Stack Developer and Data Scientist**.  \\n\\nThat's a pretty cool combination of skills!  \\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "response = with_msg_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"What is my working Profession?\")], \"language\": \"English\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi, I am Parth', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hey!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like to eat Ice Cream and my favouraite flavour is Cookies and cream.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Very Good.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is 5 + 5?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='10', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='No Problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Having Fun!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Adding a limit to the chatbot history limit\n",
    "\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 90,\n",
    "    strategy = \"last\",\n",
    "    token_counter = model,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on = \"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a good assistant\"),\n",
    "    HumanMessage(content='Hi, I am Parth'),\n",
    "    AIMessage(content='Hey!'),\n",
    "    HumanMessage(content='I like to eat Ice Cream and my favouraite flavour is Cookies and cream.'),\n",
    "    AIMessage(content='Very Good.'),\n",
    "    HumanMessage(content='What is 5 + 5?'),\n",
    "    AIMessage(content='10'),\n",
    "    HumanMessage(content='Thanks'),\n",
    "    AIMessage(content='No Problem!'),\n",
    "    HumanMessage(content='Having Fun!'),\n",
    "    AIMessage(content='Yes!'),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked me \"What is 5 + 5?\".  \\n\\nI\\'m ready for another one if you have it! üòä  \\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Passing the trimmer t a chain\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages = itemgetter(\"messages\") | trimmer) | prompt | model\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content = \"What mathematics problem i asked you?\")],\n",
    "        \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_msg_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a large language model, I have no memory of past conversations. To help me answer your question, please tell me what math problem you asked! üòä  \\n\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_msg_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"What math problem did i ask for?\")], \"language\": \"English\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
